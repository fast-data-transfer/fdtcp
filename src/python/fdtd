#!/usr/bin/env python2.7
"""
fdtcp project
https://twiki.cern.ch/twiki/bin/view/Main/PhEDExFDTIntegration
FDT service wrapper (FDT daemon - fdtd) PYRO daemon
Invokes FDT Java client / server party
FDT Java instances are created as new processes rather than threads which
    can't be killed if necessary, e.g. when transfer hangs.
"""
from __future__ import print_function
import os
import sys
import signal
import time
import threading
import resource
from threading import Lock
import apmon
from psutil import Process
from psutil import NoSuchProcess
import Pyro4
import Pyro4.core
from Pyro4.errors import PyroError
from fdtcplib.utils.Executor import Executor
from fdtcplib.utils.Executor import ExecutorException
from fdtcplib.utils.Config import Config
from fdtcplib.utils.Logger import Logger
from fdtcplib.utils.utils import getHostName
from fdtcplib.utils.utils import getOpenFilesList
from fdtcplib.common.TestAction import TestAction
from fdtcplib.common.ReceivingServerAction import ReceivingServerAction
from fdtcplib.common.SendingClientAction import SendingClientAction
from fdtcplib.common.CleanupProcessesAction import CleanupProcessesAction
from fdtcplib.common.errors import ServiceShutdownBySignal
from fdtcplib.common.errors import FDTDException
from fdtcplib.common.errors import AuthServiceException
from fdtcplib.common.errors import PortReservationException
from fdtcplib.common.errors import TimeoutException
from fdtcplib.utils.Config import ConfigurationException


class PortReservation(object):
    """
    Class holds information about reserving ports.
    Shall remove occurrences of Address already in use, etc
    See #38
    """
    def __init__(self, portMin, portMax):
        class Port(object):
            """ Port class """
            def __init__(self):
                self.port = 0
                self.reservedTimes = 0
                self.reservedNow = False

        portRange = range(portMin, portMax + 1)
        self.ports = [Port() for dummyi_ in range(len(portRange))]
        for port, portrange in zip(self.ports, portRange):
            port.port = portrange
        # just a counter of taken port
        self.numTakenPorts = 0
        # will be secured by lock, mutex access to port
        # reservation / releasing
        self.lock = threading.Lock()

    def reserve(self):
        """
        Reserve works on round-robin, so that the oldest released port will
        be re-used (shall prevent any 'already in use' error, 'could not
        bind ...' problems since the timeouts shall be well over given
        decent number of possible ports).
        """
        if len(self.ports) == self.numTakenPorts:
            raise PortReservationException("No free port to reserve. "
                                           "%s ports taken." %
                                           self.numTakenPorts)
        self.lock.acquire(True)  # block
        candid = self.ports[0]
        for port in self.ports:
            if (not port.reservedNow and
                    port.reservedTimes < candid.reservedTimes):
                candid = port
                break
        else:
            # no other port was assigned, take the first one
            candid = self.ports[0]
        self.numTakenPorts += 1
        candid.reservedTimes += 1
        candid.reservedNow = True
        self.lock.release()
        return candid.port

    def release(self, portToRel):
        """
        Release currently occupied port.
        """
        msg = ("Trying to release a port which is not currently "
               "reserved (%s)." % portToRel)
        self.lock.acquire(True)  # block
        try:
            for port in self.ports:
                if port.port == portToRel:
                    if not port.reservedNow:
                        raise PortReservationException(msg)
                    port.reservedNow = False
                    self.numTakenPorts -= 1
                    break
            else:
                raise PortReservationException(msg)
        finally:
            self.lock.release()


@Pyro4.expose
class FDTDService(object):
    """
    PYRO service invoked remotely (PYRO daemon)
    Have only very simplistic class - it's exposed to calls from network.
    """

    def __init__(self, logger, conf, apMon, fdtd):
        """
        Service / daemon has to have reference to the FDT daemon
        object (fdtd) because of administrative actions such as
        clean up of running processes initiated by the remote
        fdtcp client.
        """
        # this logger is the main daemon (fdtd) logger, if configured
        # each transfer request (which consists of multiple sub-request
        # (network calls)) can be logged into a separate file
        self.logger = logger
        self.conf = conf
        self.apMon = apMon
        self.fdtd = fdtd
        self.stopFlag = False
        self.initiatedTest = False

    def handleServiceStopped(self):
        """TODO doc """
        msg = "%s stopped or is being shutdown ..." % self.__class__.__name__
        self.logger.error(msg)
        raise PyroError(msg)

    def getSeparateLogger(self, action):
        """
        Check if there already is an associated logger on a possibly
        running executor, used that one (do not re-initialize)
        """
        tId = ""
        if 'id' in action.keys():
            tId = action['id']
        elif 'transferId' in action.keys():
            tId = action['transferId']
        executor = self.fdtd.getExecutor(tId)
        if executor:
            logger = executor.logger
        else:
            # reinitialize the logger
            # log either into the location of the main log or into /tmp
            if self.conf.get("logFile"):
                logDir = os.path.dirname(self.conf.get("logFile"))
            else:
                logDir = "/tmp"
            logFileName = os.path.join(logDir, "transfer-%s.log" % tId)
            logFile = logFileName
            logger = Logger(name="transfer",
                            logFile=logFile,
                            level=self.conf.get("debug"))
        return logger

    def updateAction(self, action, logger):
        if 'conf' not in action.keys():
            action['conf'] = self.conf
        if 'caller' not in action.keys():
            action['caller'] = self.fdtd
        if 'apmonObj' not in action.keys():
            action['apmonObj'] = self.apMon
        if 'logger' not in action.keys():
            action['logger'] = logger


    def service(self, action):
        """ Main call which will make sure that all proxies are stored and available """
        msg = ("Request received: %s" %  action)
        self.logger.debug(msg)
        # numFiles, filesStr = getOpenFilesList()
        # self.logger.debug("Logging open files: %s items:\n%s" %
        #                  (numFiles, filesStr))
        # should use separate, transfer request related log files?
        # logs sub-calls belonging to the same transfer will be appended
        transferSeparateLogFile = self.conf.get("transferSeparateLogFile")
        if transferSeparateLogFile:
            logger = self.getSeparateLogger(action)
            self.logger.debug("Logging separately into file %s" %
                              logger.logFile)
        else:
            # use the main logger
            logger = self.logger

        if self.stopFlag:
            self.handleServiceStopped()

        # this performs the request from the remote client
        self.updateAction(action, logger)
        action['logger'] = logger
        if action['action'] == 'TestAction':
            realAction = TestAction(action)
        elif action['action'] == 'ReceivingServerAction':
            realAction = ReceivingServerAction(action)
        elif action['action'] == 'SendingClientAction':
            realAction = SendingClientAction(action)
        elif action['action'] == 'CleanupProcessesAction':
            realAction = CleanupProcessesAction(action)
        else:
            raise
        try:
            realAction.execute()
            # Also move it back with not a private member
            self._pyroDaemon.register(realAction)
            return realAction
        finally:
            msg = ("End of request %s serving.\n%s\n\n\n" %
                   (action['action'], 78 * '-'))
            if transferSeparateLogFile:
                # issue #24 - fdtd - logging into separate files fails on
                # failed transfer. problem was here - logger.close() closes
                # the logger when in case of a request which remains in
                # processing - ReceivingServerAction do not re-initialize
                # the logger if it's already open and close it
                # only after related CleanupProcessesAction
                # by implementing above, the bug
                # #41 - Too many open files (fdtd side) was
                # introduced - separate loggers should be closed except on
                # ReceivingServerAction and SendingClientAction, they will
                # be closed by associated CleanupProcessesAction
                # related issues: #41:comment:8
                logger.debug(msg)
                if action['action'] not in ['ReceivingServerAction', 'SendingClientAction']:
                    logger.close()
            # numFiles, filesStr = getOpenFilesList()
            # self.logger.debug("Logging open files: %s items:\n%s" %
            #                  (numFiles, filesStr))
            self.logger.debug(msg)

    def setStop(self):
        """
        TODO: should be secured so that it is not called from outside ...
        """
        self.stopFlag = True
        self.logger.debug("%s service stop flag set." %
                          self.__class__.__name__)


class FDTD(object):
    """
    FDTD - daemon object, wrapper object to PYRO services, keeps track
    of associated running processes.
    """
    _name = None

    def __init__(self, conf, apMon, logger):
        self.name = self.__class__.__name__
        self.conf = conf
        self.apMon = apMon  # MonALISA ApMon monitoring instance
        self.logger = logger
        self.pyroDaemon = None
        self.logger.debug("Creating instance of %s ..." % self._name)

        # tracking ports occupied by already started FTD Java servers
        # ports are release once the FDT server finishes or is killed
        try:
            portRangeStr = self.conf.get("portRangeFDTServer")
            portMin, portMax = [int(i) for i in portRangeStr.split(',')]
        except (ValueError, IndexError) as ex:
            raise FDTDException("Incorrect format of port range definition: "
                                "'%s', reason: %s" % (portRangeStr, ex))
        # range of all possible ports reserved for FDT Java
        self.portMgmt = PortReservation(portMin, portMax)

        # dictionary of currently running processes spawned from the
        # PYRO service used to query status, clean up (terminate, kill)
        # when shutting down, key is id of the ExecutorAction, this
        # dictionary needs exclusive access
        self.executors = {}
        self.executorsLock = Lock()

        try:
            port = int(self.conf.get("port"))
        except (ValueError, TypeError) as ex:
            raise FDTDException("Can't start %s, wrong port, reason: %s" %
                                (self._name, ex))

        host = self.conf.get("hostname") or getHostName()

        # multiple signals may be used later for stop, stop-force, etc
        signal.signal(signal.SIGHUP, self._signalHandler)
        signal.signal(signal.SIGTERM, self._signalHandler)
        signal.signal(signal.SIGUSR1, self._signalHandler)
        signal.signal(signal.SIGALRM, self._signalHandler)

        self.initPYRO(host, port)
        self.service = FDTDService(self.logger, self.conf, self.apMon, self)

        self.logger.info("%s daemon object initialised." % self._name)

    def initPYRO(self, host, port):
        """
        Initialise the PYRO service, start PYRO daemon.
        Insist on exactly this port for the service.
        """
        self.logger.debug("Trying to bind to '%s:%s' ..." % (host, port))
        try:
            # insist on exactly this port
            self.pyroDaemon = Pyro4.core.Daemon(host=host,
                                                port=port)
        except PyroError as ex:
            msg = ("PYRO service could not start (port:%s), reason: %s" %
                   (port, ex))
            raise FDTDException(msg)

        self.logger.info("PYRO service is running on %s:%s" %
                         (host, port))

    def getFreePort(self):
        """
        Reserve a free port in a synchronized fashion.
        """
        port = self.portMgmt.reserve()
        self.logger.debug("Port '%s' is now reserved." % port)
        return port

    def releasePort(self, port):
        """
        Release a port in a synchronized fashion.

        """
        self.portMgmt.release(port)
        self.logger.debug("Port '%s' released." % port)

    def checkExecutorPresence(self, executor):
        """
        Return True of executor.id is already registered in the
        _executors container, False otherwise.

        """
        if executor.id in self.executors:
            return True
        else:
            return False

    def addExecutor(self, executor):
        """TODO doc"""
        # when logging, use the request-associated logger, not this
        # instance's one
        if self.checkExecutorPresence(executor):
            # there another check for this in Executor.execute() so this
            # shall never happen, at least when Executor is always used
            msg = ("There already is executor associated with request "
                   "id '%s' in FDTD container! Duplicate request? Something "
                   "wasn't not cleared up properly?" % executor.id)
            raise FDTDException(msg)
        else:
            self.executorsLock.acquire(True)
            self.executors[executor.id] = executor
            total = len(self.executors)
            self.executorsLock.release()
            executor.logger.debug("%s added to the FDTD executors container "
                                  "(total %s items)." % (executor, total))

    def removeExecutor(self, executor):
        """
        Removes Executor instance e from the _executors container when it's
        sure the associated process finished. Also free the port.
        For logging use the request-associated logger, not this
        instance's one
        """
        self.executorsLock.acquire(True)
        total = len(self.executors)
        executor.logger.debug("FDT executors container before removing attempt "
                              "(total %s items)." % total)
        try:
            del self.executors[executor.id]
            executor.logger.critical("Process of executor id '%s' (process "
                                     "PID: %s) still exists! Not removing from "
                                     "FDTD executors container." %
                                     (executor.id, executor.proc.pid))
            # put it back
            self.executors[executor.id] = executor
        except KeyError:
            executor.logger.error("Executor id '%s' not present in the FDTD "
                                  "executors container." % executor.id)
        except NoSuchProcess:
            executor.logger.debug("Process doesn't exist now, ok (PID: %s, %s)." %
                                  (executor.proc.pid, executor.id))
            if executor.port:
                try:
                    self.releasePort(executor.port)
                except PortReservationException as ex:
                    msg = "Port release failed, reason: %s" % ex
                    if executor.logger is not self.logger:
                        self.logger.critical(msg)
                    executor.logger.critical(msg)
                else:
                    executor.logger.debug("Port '%s' should be released." % executor.port)
            else:
                executor.logger.debug("Port property is not set, nothing to release.")
            total = len(self.executors)
            executor.logger.debug("%s removed from the FDTD executors container "
                                  "(total %s items)." % (executor, total))
        self.executorsLock.release()

    def getExecutor(self, idE):
        """
        Returns executor reference from the executors container based on
        the given id (id of the transfer is the same as of the executor)
        and if it doesn't exist, return None.
        """
        self.executorsLock.acquire(True)
        exe = None
        try:
            exe = self.executors[idE]
        except KeyError:
            exe = None
        self.executorsLock.release()
        return exe

    def killProcess(self, idE, logger, waitTimeout=True):
        """
        id is a key into self._executors pool
        waitTimeout - if set, killTimeout associated with the
            Executor instance is taken into account, ignored otherwise.

        """
        logger.debug("Processing clean up / process kill request for "
                     "transfer id '%s' ..." % idE)
        if idE in self.executors:
            executor = self.executors[idE]
            msg = self._killProcess(executor, logger, waitTimeout=waitTimeout)
            logger.info(msg)
            self.removeExecutor(executor)
        else:
            msg = ("No such process/action id '%s' in executors "
                   "containers." % idE)
            logger.error(msg)
        return msg

    def start(self):
        """ TODO doc """
        objServiceName = self.service.__class__.__name__
        uri = self.pyroDaemon.register(self.service, objServiceName)
        self.logger.info("%s waiting for requests ... ('%s' uri: '%s')" %
                         (self._name, objServiceName, uri))
        # the flow stops at this call - can be interrupted by a signal
        # (and handler is called) when running as a proper daemon in production
        # or from Keyboard (development mode)
        self.pyroDaemon.requestLoop()

    def _killProcess(self, executor, logger, waitTimeout=True):
        """
        Method to perform cleaning up / killing of running processes.
        If the process runs, check process's killTimeout, wait that time
        if it finishes, if not kill it.
        The issues is e.g. FDT Java server may still be flushing its buffers.

        waitTimeout - if set, killTimeout associated with the
            Executor instance is taken into account, ignored otherwise.

        The logger variable may either be associated with a separate PYRO
        received request, i.e. associated with CleanupProcessesAction or if
        this method is called from within this same class, it would
        be self.logger. The latter case is e.g. when _killProcess is called
        after fdtd received shutdown signal. If this causes issues,
        executor.logger can be considered.
        """
        exe = executor
        logger.debug("Going to poll state: %s ..." % exe)

        # do this check if there is no timeout associated and
        # process has already finished
        if exe.proc.poll() > -1:
            returnCode = exe.proc.wait()
            msg = ("Process PID: %s finished, returncode: '%s'\nlogs:\n%s" %
                   (exe.proc.pid, returnCode, exe.getLogs()))
            return msg

        if exe.killTimeout > 0 and waitTimeout:
            logger.debug("Going to wait timeout: %s [s], waitTimeout: %s" %
                         (exe.killTimeout, waitTimeout))
            for dummycounter in range(exe.killTimeout):
                if exe.proc.poll() > -1:
                    returnCode = exe.proc.wait()
                    msg = ("Process PID: %s finished, returncode: "
                         "'%s'\nlogs:\n%s" %
                         (exe.proc.pid, returnCode, exe.getLogs()))
                    return msg
                else:
                    logger.debug("Process PID: %s still runs, waiting ..." %
                                 exe.proc.pid)
                    time.sleep(1)
            else:
                # waiting period exhausted
                logger.warn("Process PID: %s still has not finished "
                            "(timeout: %s [s]), going to kill it ..." %
                            (exe.proc.pid, exe.killTimeout))
        else:
            logger.warn("Going to kill process PID: %s, kill wait timeout: "
                        "%s [s] waitTimeout: %s ..." %
                        (exe.proc.pid, exe.killTimeout, waitTimeout))

        # python 2.4.3 Popen object has no attribute kill - can't do
        # executor.proc.kill() have to kill via external kill OS command
        try:
            # TODO
            # SIGTERM doesn't stop properly all client threads in
            # AuthService GSIBaseServer, have to use brute force SIGKILL
            if exe.userName:
                opt = dict(pid=int(exe.proc.pid+1), sudouser=exe.userName)
                command = self.conf.get("killCommandSudo") % opt
            else:
                opt = dict(pid=int(exe.proc.pid+1))
                command = self.conf.get("killCommand") % opt

            killExec = Executor(exe.id,
                                command,
                                blocking=True,
                                logger=logger)
            dummyoutput = killExec.execute()
        except ExecutorException as ex:
            msg = ("Error when killing process PID: %s (kill process: %s), "
                   "reason: %s\nlogs from the killed-attempt process:\n%s" %
                   (exe.proc.pid, killExec, ex, exe.getLogs()))
            # will be logged locally with the fdtd daemon
            logger.error(msg)
            # will be propagated and logged with remote fdtcp client
            raise FDTDException(msg)
        else:
            logs = exe.getLogs()
            # it was observed that sometimes
            # OSError [Errno 10] No child processes
            # is raised here, probably when the process already finished?
            # # check #8 description
            try:
                code = exe.proc.wait()
            except OSError as ex:
                logger.error("Could not retrieve the returncode, "
                             "reason: %s" % ex)
                code = "unknown: %s" % ex
            msg = "%s killed, returncode: '%s'\nlogs:\n%s" % (exe, code, logs)
            logger.debug("Checking that process was killed ...")
            try:
                proc = Process(exe.proc.pid)
            except NoSuchProcess as ex:
                logger.debug("Process PID: %s doesn't exist now." %
                             exe.proc.pid)
            else:
                logger.error("Process PID: %s still exists ('%s')." % proc)
            return msg

    def shutdown(self):
        """
        Shutdown sequence of the fdtd daemon.
        Cleaning all running processes (FDT Java).

        """
        self.logger.warn("Shutting down %s ..." % self._name)

        # do this as soon as possible, before PYRO daemon goes down so that
        # clients connected beyond this point are notified by
        # PyroError in response
        self.service.setStop()

        self.logger.warn("PYRO internal daemon shutdown flag set.")

        self.logger.warn("%s associated processes running." %
                         len(self.executors))
        self.executorsLock.acquire()
        loggersToClose = []
        try:
            for idE in self.executors:
                # here calling ._killProcess with the FDTD instance logger
                # this operation is not related to any request
                msg = self.killProcess(self.executors[idE],
                                       self.logger,
                                       waitTimeout=False)
                self.logger.info(msg)
                # check for separate log files, if it's open, close
                exe = self.executors[idE]
                if (exe.logger is not self.logger) and exe.logger.isOpen:
                    loggersToClose.append(exe.logger)
        except FDTDException as ex:
            self.logger.error(ex)
        self.executorsLock.release()

        """
        Calling pyroDaemon.closedown() is troublesome and in fact not clear
        if necessary at all, unlike pyroDaemon.shutdown()
        It seems that it didn't matter calling closedown() before or after
        stopping FDT Java processes which, in the case of client action
        which is blocking, were attached to a hanging PYRO call.
        See Ticket #22 - fdtd shutdown sequence misfunctioning for details
        Interestingly, preventing hanging via signal/alarm also not always
        reliably worked.
        Leave comment out for reference.
        self.logger.warn("Going to call pyroDaemon.closedown() ...")
        try:
            signal.alarm(3) # raise alarm in timeout seconds
            self.pyroDaemon.closedown()
            self.logger.warn("pyroDaemon.closedown() call successful.")
        except TimeoutException:
            self.logger.error("pyroDaemon.closedown() hanging, continue "
                              "forced. End of shutdown sequence.")
        else:
            self.logger.warn("%s stopped, whole shutdown sequence "
                             "successful." % self._name)
        """
        self._checkDaemonReleasedPort()
        # if there were any executors with their own dedicated separated
        # log files, these shall be closed now
        for loger in loggersToClose:
            if loger.isOpen():
                loger.warn("Service is being shutdown, closing executor open "
                           "log file '%s'" % loger.myLogFile)
                loger.close()
        self.logger.warn("%s stopped, whole shutdown sequence "
                         "successful." % self._name)

    def _checkDaemonReleasedPort(self):
        """
        Method periodically checks that the port of the daemon is released.
        It's useful esp. when running tests which are binding the same
        port or when restarting the service.
        """
        port = self.conf.get("port")
        port = int(port)
        pid = os.getpid()
        self.logger.debug("Going to check that FDTD daemon (PID: %s) "
                          "released its port %s ..." % (pid, port))
        process = Process(pid)
        stillBound = True
        while stillBound:
            # connection(fd=115, family=2, type=1,
            #       local_address=('10.0.0.1', 48776),
            #       remote_address=('93.186.135.91', 80),
            #       status='ESTABLISHED')
            conns = process.connections()
            for conn in conns:
                locaddr = conn.local_address
                self.logger.debug("FDTD daemon connections: '%s'" %
                                  str(conn))
                if locaddr[1] == port:
                    self.logger.debug("\tnot yet released, waiting ...")
                    time.sleep(0.2)
                    continue
            else:
                # exhausted all connections (if any), port must be
                # released now
                self.logger.debug("FDTD daemon released port %s." % port)
                stillBound = False

    def _signalHandler(self, signum, dummyframe):
        """ TODO doc """
        if signum == signal.SIGALRM:
            self.logger.warn("SIGALRM signal %s caught, raising "
                             "exception." % signum)
            raise TimeoutException("Timeout exception.")
        if signum == signal.SIGHUP:
            # SIGHUP: the service goes down only if there is no transfer
            # in progress
            self.logger.warn("SIGHUP signal %s caught, checking for running "
                             "transfer(s) ..." % signum)
            self.executorsLock.acquire(True)
            execCounter = 0
            for exe in self.executors.values():
                if exe.id == "AuthService":
                    continue  # AuthService is present all the time, ignore
                else:
                    # other executor IDs - transfer - do not shutdown then
                    self.logger.debug("In executors container: %s" % exe)
                    execCounter += 1
            self.executorsLock.release()
            self.logger.debug("Signal handler: %s transfers running." %
                              execCounter)
            numFiles, filesStr = getOpenFilesList()
            self.logger.debug("Signal handler: open files: %s items:\n%s" %
                              (numFiles, filesStr))
            if execCounter == 0:
                msg = ("SIGHUP signal %s - no transfer(s) in progress, "
                       "shutdown." % signum)
                raise ServiceShutdownBySignal(msg)
            else:
                self.logger.warn("SIGHUP signal %s - transfer(s) in "
                                 "progress, ignored." % signum)
        if signum == signal.SIGTERM:
            numFiles, filesStr = getOpenFilesList()
            self.logger.debug("Signal handler: open files: %s "
                              "items:\n%s" % (numFiles, filesStr))
            msg = ("SIGTERM signal %s caught, shutting down "
                   "(forced) ..." % signum)
            # raise exception rather than calling .shutdown() directly,
            # this way it can be only shutdown from one place
            raise ServiceShutdownBySignal(msg)


class ConfigFDTD(Config):
    """
    Class holding various options and settings which are either predefined
    in the configuration file, overriding from command line options is
    considered.
    """

    # mandatory configuration values, integers
    _mandatoryInt = ["port",
                     "portAuthService",
                     "fdtSendingClientKillTimeout",
                     "fdtServerLogOutputTimeout",
                     "fdtReceivingServerKillTimeout"]
    # "authServiceLogOutputTimeout"]
    # mandatory configuration values, strings
    _mandatoryStr = ["fdtSendingClientCommand",
                     "fdtReceivingServerCommand",
                     "debug",
                     "portRangeFDTServer",
                     "transferSeparateLogFile",
                     "fdtServerLogOutputToWaitFor",
                     "killCommandSudo",
                     "killCommand",
                     "daemonize"]
    # "authServiceLogOutputToWaitFor",
    # "authServiceCommand",

    def __init__(self, args):
        # 1 - shall point to the same directory
        currDir = os.path.abspath(__file__).rsplit(os.sep, 1)[0]
        currDirConfig = os.path.join(currDir, "fdtd.conf")
        # consider only config file being in the same directory
        # as well as in the system config directory location
        self.options = {}
        # mandatory configuration values, integers
        self.mandatoryInt = ["port",
                             "portAuthService",
                             "fdtSendingClientKillTimeout",
                             "fdtServerLogOutputTimeout",
                             "fdtReceivingServerKillTimeout"]
        # "authServiceLogOutputTimeout"]
        # mandatory configuration values, strings
        self.mandatoryStr = ["fdtSendingClientCommand",
                             "fdtReceivingServerCommand",
                             "debug",
                             "portRangeFDTServer",
                             "transferSeparateLogFile",
                             "fdtServerLogOutputToWaitFor",
                             "killCommandSudo",
                             "killCommand",
                             "daemonize"]
    # "authServiceLogOutputToWaitFor",
    # "authServiceCommand",
        locations = [currDirConfig, "/etc/fdtcp/fdtd.conf"]
        self.usage = None
        Config.__init__(self, args, locations, mandInt=self.mandatoryInt, mandStr=self.mandatoryStr)

    def processCommandLineOptions(self, args):
        """
        This method gets called from base class.

        """
        helps = "debug output level, for possible values see the config file"
        self.parser.add_option("-d", "--debug", help=helps)
        helps = "port number on which to start local fdtd service"
        self.parser.add_option("-p", "--port", help=helps)
        helps = "configuration file for fdtd service"
        self.parser.add_option("-c", "--config", help=helps)
        helps = "print this help"
        self.parser.add_option("-h", "--help", help=helps, action='help')
        helps = "specify hostname of this machine"
        self.parser.add_option("-H", "--hostname", help=helps)
        helps = "output log file"
        self.parser.add_option("-l", "--logFile", help=helps)
        helps = "run the service on the background as daemon process"
        self.parser.add_option("-a",
                               "--daemonize",
                               action="store_true",
                               help=helps)
        helps = "file to store PID of the daemon process (when running \
                 with daemonize)"
        self.parser.add_option("-i", "--pidFile", help=helps)
        helps = "each transfer related requests will be logged in a \
                separate log file"
        self.parser.add_option("-s",
                               "--transferSeparateLogFile",
                               action="store_true", help=helps)

        # opts - new processed options, items defined above as attributes
        # args - remainder of the input array
        opts, args = self.parser.parse_args(args=args)

        # want to have _options a dictionary, rather than instance
        # some Values class from within optparse.OptionParser
        #self._options = opts
        self.options = eval(str(opts))


class AuthService(object):
    """
    Class for encapsulating process of AuthService - Grid authentication
    service - runs in a single instance per fdtd
    Shutdown of the process is taken care of by FDTD instance, once this
    process is started, it is registered with FDTD which will kill it
    when it goes down.
    """

    # TODO
    # may need to flush its buffers with output, though there should not
    # significant amount of data, but this would have to done either from
    # Java or something will have automatically poll this AuthService
    # executor ...

    def __init__(self, fdtd, conf, logger):
        self.fdtd = fdtd
        self.conf = conf
        self.logger = logger

        self.logger.debug("Creating instance of AuthService ...")
        self.options = {}
        return

    #    self.options["port"] = self.conf.get("portAuthService")
    #    command = self.conf.get("authServiceCommand") % self.options
    #    toWaitFor = self.conf.get("authServiceLogOutputToWaitFor")
    #    timeout = self.conf.get("authServiceLogOutputTimeout")
    #    self.executor = Executor("AuthService",
    #                             command=command,
    #                             blocking=False,
    #                             caller=self.fdtd,
    #                             logOutputToWaitFor=toWaitFor,
    #                             logOutputWaitTime=timeout,
    #                             logger=self.logger)
    #    try:
    #        output = self.executor.execute()
    #        self.logger.debug(output)
    #    except ExecutorException as ex:
    #        m = "Could not start AuthService, reason: %s" % ex
    #        raise AuthServiceException(m)


def daemonize(conf, logger):
    """
    Store pid of the current process into pidFile and fork the daemon
    process (FDTD).
    Daemonization recipe compiled from several sources and compared to
    a number of recipes available on the internet.
    """
    logger.info("Preparing for daemonization (parent process "
                "PID: %s) ..." % os.getpid())

    # check that there is a log defined, otherwise fail - need to
    # redirect stdout, stderr stream into this file
    if not logger.logFile:
        logger.fatal("No log file defined, necessary when running as "
                     "daemon, exit.")
        logger.close()
        sys.exit(1)
    # check if there is pidFile defined - necessary in daemon mode
    if not conf.get("pidFile"):
        logger.fatal("No pid file defined, necessary when running as "
                     "daemon, exit.")
        logger.close()
        sys.exit(1)

    pidFile = conf.get("pidFile")
    # try opening the file for append - if exists - fail: fdtd.py might
    # be running or the file was left behind
    if os.path.isfile(pidFile):
        logger.fatal("File '%s' exists, can't start, remove it first." %
                     pidFile)
        logger.close()
        sys.exit(1)

    # check if the pidFile is writeable
    try:
        pidFileDesc = open(pidFile, 'w')
        pidFileDesc.close()
    except IOError as ex:
        logger.fatal("Can't access PID file '%s', reason: %s" %
                     (pidFile, ex))
        logger.close()
        sys.exit(1)

    # daemonization forking ...
    if os.fork() != 0:
        # exit parent code
        sys.exit(0)

    # decouple from parent environment
    os.chdir("/")
    os.setsid()
    os.umask(0)
    # don't change current working directory (os.chdir("/"))

    # fork again so we are not a session leader
    if os.fork() != 0:
        sys.exit(0)

    # output streams redirection into the log file
    # log file is already used by logger, concurrent writes may
    # get messy ... ideally there however should not be any logging
    # into streams from now on ...
    numFiles, filesStr = getOpenFilesList()
    logger.debug("Logging open files: %s items:\n%s" % (numFiles, filesStr))
    logger.debug("The process is daemonized, redirecting "
                 "stdout, stderr, stdin descriptors ...")
    for fout in sys.stdout, sys.stderr:
        fout.flush()
    logFile = file(logger.logFile, "a+", 0)  # buffering - 0 (False)
    devNull = file("/dev/null", 'r')
    os.dup2(logFile.fileno(), sys.stdout.fileno())
    os.dup2(logFile.fileno(), sys.stderr.fileno())
    os.dup2(devNull.fileno(), sys.stdin.fileno())

    logger.debug("Redirecting streams is over.")
    numFiles, filesStr = getOpenFilesList()
    logger.debug("Logging open files: %s items:\n%s" % (numFiles, filesStr))

    # finally - the daemon process code, first store it's PID into file
    pid = os.getpid()
    logger.info("Running as daemon process: PID: %s (forked), "
                "PID file: '%s'" % (pid, pidFile))
    pidFileDesc = open(pidFile, 'w')
    pidFileDesc.write(str(pid))
    pidFileDesc.close()

    logger.debug("End of daemonization.")


def startApplication(conf, logger):
    """
    Main daemon function.

    Issues with moving ApMon initialization around:
        - if here, there is init msg which doesn't appear now for the
          streams were closed in daemonize()
        - moving before the streams were closed (i.e. moving to main())
          caused issues when calling apMon.free() - the flow stopped
          thre for unknown reason yet no exception was raised.
        Leave ApMon like this, as is!
    """
    apMon = None
    apMonDestConf = conf.get("apMonDestinations")
    if apMonDestConf:
        apMonDestinations = tuple(apMonDestConf.split(','))
        logger.info("Initializing MonALISA ApMon, "
                    "destinations: %s ..." % (apMonDestinations,))
        apMon = apmon.ApMon(apMonDestinations)
        apMon.enableBgMonitoring(True)
    else:
        logger.info("MonALISA ApMon is not enabled, no "
                    "destinations provided.")

    # use DNS names rather than IP address
    # Pyro.config.PYRO_DNS_URI = True
    # TODO: Force it from config to be a hostname...

    daemon = None
    try:
        try:
            daemon = FDTD(conf, apMon, logger)
            dummyauthService = AuthService(daemon, conf, logger)
            daemon.start()
        except AuthServiceException as ex:
            msg = "Exception during AuthService startup, reason: %s" % ex
            print(msg)
            logger.fatal(msg)
        except FDTDException as ex:
            msg = "Exception during FDTD initialization, reason %s" % ex
            print(msg)
            logger.fatal()
        except KeyboardInterrupt:
            msg = "Interrupted from keyboard ..."
            print(msg)
            logger.fatal(msg)
        except ServiceShutdownBySignal as ex:
            msg = "Service was shutdown by signal, reason: %s" % ex
            print(msg)
            logger.fatal(msg)
        except Exception as ex:
            msg = "Exception was caught ('%s'), reason: %s" % (ex.__class__.__name__, ex)
            print(msg)
            logger.fatal(msg, traceBack=True)
    finally:
        if daemon:
            try:
                daemon.shutdown()
            except Exception as ex:
                logger.fatal("Exception occurred during shutdown sequence, "
                             "reason: %s" % ex, traceBack=True)
        try:
            if apMon:
                logger.debug("Releasing ApMon ...")
                apMon.free()

            # if daemonize, pidFile should have been created,
            # delete it now when shutting down
            if conf.get("daemonize"):
                pidFile = conf.get("pidFile")
                logger.info("Deleting the PID file '%s' ... " % pidFile)
                try:
                    os.remove(pidFile)
                    logger.debug("File '%s' removed." % pidFile)
                except OSError as ex:
                    logger.error("Could not remove PID file '%s', "
                                 "reason: %s" % (pidFile, ex))
        except Exception as ex:
            logger.fatal("Exception occurred during shutdown-cleanup, "
                         "reason: %s" % ex, traceBack=True)
        logger.close()


def main():
    """ TODO doc """
    # all values and action information held in the conf object
    optBackup = sys.argv[:]
    try:
        conf = ConfigFDTD(sys.argv[1:])
        conf.sanitize()
    except ConfigurationException as ex:
        print("fdtd failed to start, reason: %s" % ex)
        sys.exit(1)

    logger = Logger(name="fdtd",
                    logFile=conf.options.get("logFile"),
                    level=conf.options.get("debug"))
    # ticket #35 - mercurial expandable keywords in the code
    # information from the SCM (expandable keywords)
    versionInfo = dict(Revision="$Revision: 99536bb6d942 $",
                       Tags="$Tags: tip $")
    logger.info("fdtd starting ... version: %s" %
                logger.pprintFormat(versionInfo))
    logger.debug("Search sys.path:\n%s\n" % logger.pprintFormat(sys.path))
    logger.debug("PYRO_STORAGE: '%s'" % os.environ.get("PYRO_STORAGE"))
    numOpen = resource.getrlimit(resource.RLIMIT_NOFILE)
    logger.debug("Number of allowed open files: %s" % (numOpen,))

    logger.debug("Input command line arguments: '%s'" % optBackup)
    logger.debug("Configuration values (processed):\n%s\n" %
                 logger.pprintFormat(conf.options))

    # daemonization
    if conf.options.get("daemonize"):
        daemonize(conf, logger)
    else:
        logger.info("Starting the service on foreground ...")

    startApplication(conf, logger)


if __name__ == "__main__":
    main()
